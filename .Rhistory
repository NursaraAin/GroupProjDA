6+3
ans = 6+3
print(ans)
ans+100
print("#Price after 50% discount\n",fifty)
print("#Calculate the price after discount")
price = readline(prompt = "price")
thirty = price*(1-0.3)
print
print
print
print("#Calculate the price after discount")
price = readline(prompt = "price")
1fifty = price*0.5
fifty = price*0.5
fifty = price*0.5
#Calculate the price after discount
price = as.numeric(readline(prompt = "price"))
fifty = price*0.5
thirty = price*(1-0.3)
ten = price*(1-0.1)
#Calculate the price after discount
price = 100
#Price after 50% discount
print(price*0.5)
#Price after 30% discount
print(price*(1-0.3))
#Price after 10% discount
print(price*(1-0.1))
#Calculate the price after discount
price = 10
#Price after 50% discount
print(price*0.5)
#Price after 30% discount
print(price*(1-0.3))
#Price after 10% discount
print(price*(1-0.1))
data(breastcancer)
data(cars)
install.packages("mlbench")
BreastCancer
install.packages(caret)
install.packages("caret")
library("mlbench")
data("BreastCancer")
dim(BreastCancer)
BreastCancer[c(1,20),]
BreastCancer[20,]
BreastCancer[1:20,]
library(mlbench)
library(tidyverse)
library(dplyr)
library(car)
library(pROC)
library(MLmetrics)
library(rpart)
library(rpart.plot)
library(varImp)
library(caret)
data("BreastCancer")
BreastCancer$Id<- as.integer(BreastCancer$Id)
bc = subset(BreastCancer,select = -(Id))
breast=bc
breast$Class<-as.character(breast$Class)
breast$Class<- replace(breast$Class,breast$Class=='benign', "0")
breast$Class<- replace(breast$Class,breast$Class=='malignant', "1")
breast <- na.omit(breast)
ind <- sapply(breast, is.factor)
breast[ind] <- lapply(breast[ind], function(x) as.numeric(as.character(x)))
ind1 <- sapply(breast, is.character)
breast[ind1] <- lapply(breast[ind1], function(x) as.numeric(as.character(x)))
#LG
set.seed(7)
train_index <- sample(nrow(breast), size = round(0.75 * nrow(breast)), replace = FALSE)
train <- breast[train_index,]
test <- breast[-train_index,]
lm <- glm(formula = Class ~ ., data = train, family = binomial())
summary(lm)
vif(lm)
lm2 <- glm(formula = Class ~ ., data = train %>% select(-c(Cell.size, Epith.c.size, Mitoses)), family = binomial())
summary(lm2)
lm3 <- glm(formula = Class ~ ., data = train %>% select(-c(Cell.size, Epith.c.size, Bare.nuclei, Mitoses)), family = binomial())
summary(lm3)
pred_train_lm <- predict(lm3, train, type = 'response')
AUC_train_lm <- roc(train$Class, pred_train_lm, percent = TRUE, plot = TRUE, print.auc = TRUE)
hist(pred_train_lm,
main = "Distribution of Predicted Values",
xlab = "Predicted Values",
col = "#6baed6",
border = NULL)
accuracy <- 0
f1 <- 0
threshold <- 0
for(i in seq(0.1, 0.9, by = 0.01)){
pred_cat_train <- ifelse(pred_train_lm < i, 0, 1)
a = Accuracy(y_true = train$Class, y_pred = pred_cat_train)
b = F1_Score(y_true = train$Class, y_pred = pred_cat_train)
if(a > accuracy & b > f1){
accuracy = a
f1 = b
threshold = i
}
}
accuracy
f1
threshold
pred_test_lm <- predict(lm3, test, type = 'response')
AUC_test_lm <- roc(test$Class, pred_test_lm, percent = TRUE, plot = TRUE, print.auc = TRUE)
pred_cat_test <- ifelse(pred_test_lm >= 0.48, 1, 0)
Accuracy(y_true = test$Class, y_pred = pred_cat_test)
F1_Score(y_true = test$Class, y_pred = pred_cat_test)
ConfusionMatrix(y_true = test$Class, y_pred = pred_cat_test)
# LG
set.seed(7)
fit.glm<- train(Class~.,data=breast, method="glm", metric=metric,
trControl=trainControl)
print(fit.glm)
# LDA
lda.fit = train(Class ~ ., data=breast, method="lda",metric=metric,
trControl=trainControl)
print(lda.fit)
lm <- glm(formula = Class ~ ., data = train, family = binomial())
summary(lm)
vif(lm)
lm2 <- glm(formula = Class ~ ., data = train %>% select(-c(Cell.size, Epith.c.size, Mitoses)), family = binomial())
# LG
set.seed(7)
fit.glm<- train(Class~.,data=breast, method="glm", metric=metric,
trControl=trainControl)
# LDA
lda.fit = train(Class ~ ., data=breast, method="lda",metric=metric,
trControl=trainControl)
library(Rcpp)
fit.glm<- train(Class~.,data=breast, method="glm", metric=metric,
trControl=trainControl)
update.packages(Rcpp)
update.packages("Rcpp")
fit.glm<- train(Class~.,data=breast, method="glm", metric=metric,
trControl=trainControl)
source("C:/Users/nursa/Desktop/sem4/WIH2001/U2005391-Tutorial-8.R")
data("BreastCancer")
breast <- BreastCancer
breast <- select(breast, -1)
breast$Bare.nuclei<-as.numeric(breast$Bare.nuclei)
breast$Bare.nuclei[is.na(breast$Bare.nuclei)] <-round(mean(breast$Bare.nuclei, na.rm = T),digits = 0)
sapply(breast, class)
#check
lapply(breast, function(x) any(is.na(x)))
data <- breast
inTraining <- createDataPartition(data$Class, p = .75, list = FALSE)
training_BC <- data[ inTraining,]
testing_BC  <- data[-inTraining,]
trainControl <- trainControl(method="repeatedcv", number=10, repeats=3)
metric <- "Accuracy"
# LG
set.seed(7)
fit.glm<- train(Class~.,data=breast, method="glm", metric=metric,
trControl=trainControl)
print(fit.glm)
# LDA
lda.fit = train(Class ~ ., data=breast, method="lda",metric=metric,
trControl=trainControl)
print(lda.fit)
# GLMNET
glmnet.fit<-train(Class ~ ., data=breast, method="glmnet",metric=metric,
trControl=trainControl)
print(glmnet.fit)
# KNN
knn.fit<-train(Class ~ ., data=breast, method="knn",metric=metric,
trControl=trainControl)
print(knn.fit)
# CART
cart.fit<-train(Class ~ ., data=breast, method="rpart",metric=metric,
trControl=trainControl)
print(cart.fit)
# NB
set.seed(2)
nb.fit<-train(Class ~ ., data=breast, method="naive_bayes",metric=metric,
trControl=trainControl)
install.packages("naivebayes")
library(naivebayes)
# NB
set.seed(2)
nb.fit<-train(Class ~ ., data=breast, method="naive_bayes",metric=metric,
trControl=trainControl)
print(cart.fit)
results<-resamples(list(glm=fit.glm,lda=lda.fit,glmnet=glmnet.fit,knn=knn.fit,cart=cart.fit,nb=nb.fit))
summary(results)
dotplot(results)
library(mlbench)
library(dplyr)
library(caret)
library(Rcpp)
library(naivebayes)
data("BreastCancer")
breast <- BreastCancer
breast <- select(breast, -1)
breast$Bare.nuclei<-as.numeric(breast$Bare.nuclei)
breast$Bare.nuclei[is.na(breast$Bare.nuclei)] <-round(mean(breast$Bare.nuclei, na.rm = T),digits = 0)
sapply(breast, class)
#check
lapply(breast, function(x) any(is.na(x)))
data <- breast
inTraining <- createDataPartition(data$Class, p = .75, list = FALSE)
training_BC <- data[ inTraining,]
testing_BC  <- data[-inTraining,]
trainControl <- trainControl(method="repeatedcv", number=10, repeats=3)
metric <- "Accuracy"
# LG
set.seed(7)
fit.glm<- train(Class~.,data=breast, method="glm", metric=metric,
trControl=trainControl)
print(fit.glm)
# LDA
lda.fit = train(Class ~ ., data=breast, method="lda",metric=metric,
trControl=trainControl)
print(lda.fit)
# GLMNET
glmnet.fit<-train(Class ~ ., data=breast, method="glmnet",metric=metric,
trControl=trainControl)
print(glmnet.fit)
# KNN
knn.fit<-train(Class ~ ., data=breast, method="knn",metric=metric,
trControl=trainControl)
print(knn.fit)
# CART
cart.fit<-train(Class ~ ., data=breast, method="rpart",metric=metric,
trControl=trainControl)
print(cart.fit)
# NB
set.seed(2)
nb.fit<-train(Class ~ ., data=breast, method="naive_bayes",metric=metric,
trControl=trainControl)
print(nb.fit)
results<-resamples(list(glm=fit.glm,lda=lda.fit,glmnet=glmnet.fit,knn=knn.fit,cart=cart.fit,nb=nb.fit))
summary(results)
dotplot(results)
library(caret)
library(party)
library(e1071)
library(caTools)
library(dplyr)
library(car)
setwd("C:/Users/nursa/Desktop/sem4/WIH2001")
flower=rename(flower,slen=SepalLengthCm)
flower=rename(flower,swid=SepalWidthCm)
flower=rename(flower,plen=PetalLengthCm)
flower=rename(flower,pwid=PetalWidthCm)
flower=rename(flower,spec=Species)
flower$spec=replace(flower$spec,flower$spec=='Iris-setosa',"1")
flower$spec=replace(flower$spec,flower$spec=='Iris-versicolor',"2")
flower$spec=replace(flower$spec,flower$spec=='Iris-virginica',"3")
ind <- sapply(flower, is.factor)
flower[ind] <- lapply(flower[ind], function(x) as.numeric(as.character(x)))
ind1 <- sapply(flower, is.character)
flower[ind1] <- lapply(flower[ind1], function(x) as.numeric(as.character(x)))
flower=subset(flower,select=-c(Id))
set.seed(7267166)
trainIndex = createDataPartition(flower$spec, p = 0.7)$Resample1
flower=read.csv("Iris.csv")
flower=rename(flower,slen=SepalLengthCm)
flower=rename(flower,swid=SepalWidthCm)
flower=rename(flower,plen=PetalLengthCm)
flower=rename(flower,pwid=PetalWidthCm)
flower=rename(flower,spec=Species)
flower$spec=replace(flower$spec,flower$spec=='Iris-setosa',"1")
flower$spec=replace(flower$spec,flower$spec=='Iris-versicolor',"2")
flower$spec=replace(flower$spec,flower$spec=='Iris-virginica',"3")
ind <- sapply(flower, is.factor)
flower[ind] <- lapply(flower[ind], function(x) as.numeric(as.character(x)))
ind1 <- sapply(flower, is.character)
flower[ind1] <- lapply(flower[ind1], function(x) as.numeric(as.character(x)))
flower=subset(flower,select=-c(Id))
trainIndex = createDataPartition(flower$spec, p = 0.7)$Resample1
train = flower[trainIndex, ]
test = flower[-trainIndex, ]
print(table(flower$spec))
print(table(train$spec))
pairs(flower)
pairs(corr)
corr<-subset(flower,select=-c(spec))
pairs(corr)
tab <- table(flower$pwid) # number of occurrences for each unique value
sort(tab, decreasing = TRUE) # sort highest to lowest
tab <- table(flower$plen) # number of occurrences for each unique value
sort(tab, decreasing = TRUE) # sort highest to lowest
source("C:/Users/nursa/Desktop/sem4/WIH2001/case study is confused.R")
setwd("C:/Users/nursa/OneDrive/GroupProjDA")
library(psych)
library(caret)
library(dplyr)
library(car)
library(Metrics)
anar=read.csv("totalANAR.csv")
dt=subset(anar,select = c(regionN,Dvrregion,IndicatN,
Total.Point.estimate,Children.without.functional.difficulties.Point.estimate,
Children.with.functional.difficulties.Point.estimate,Time.period))
corPlot(cor(dt))
oor=read.csv("totalOOR.csv")
dt1=subset(oor,select = c(regionN,Dvrregion,IndicatN,
Total.Point.estimate,Children.without.functional.difficulties.Point.estimate,
Children.with.functional.difficulties.Point.estimate,Time.period))
corPlot(cor(dt1))
